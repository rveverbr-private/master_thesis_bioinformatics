{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import get_ipython\n",
    "if get_ipython():\n",
    "    get_ipython().run_line_magic(\"load_ext\", \"autoreload\")\n",
    "    get_ipython().run_line_magic(\"autoreload\", \"2\")\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import scanpy as sc\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polyptich as pp\n",
    "pp.setup_ipython()\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import scanpy as sc\n",
    "\n",
    "import polyptich as pp\n",
    "import latenta as la\n",
    "import os\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "\n",
    "import tqdm.auto as tqdm\n",
    "\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear synthetic data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes = la.Dim(500, name=\"gene\")\n",
    "cells = la.Dim(2000, name=\"cell\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = np.random.default_rng(1)\n",
    "x1 = la.Fixed(generator.uniform(size=len(cells)), definition=[cells], label=\"Linear1\")\n",
    "x2 = la.Fixed(generator.uniform(size=len(cells)), definition=[cells], label=\"Sigmoid2\")\n",
    "x3 = la.Fixed(generator.uniform(size=len(cells)), definition=[cells], label=\"Linear3\")\n",
    "\n",
    "b_value = generator.normal(1, scale=0.5, size=len(genes))\n",
    "b = la.Fixed(b_value, definition=[genes], label=\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([x1.loader.value, x2.loader.value, x3.loader.value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(X.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_a(key, genes, odds_ratio=1):\n",
    "    a = la.distributions.NormalDualMixture(\n",
    "    key=key,\n",
    "    loc1=0.0,\n",
    "    scale1=0.1,\n",
    "    loc2=0.0,\n",
    "    scale2=1,\n",
    "    logit=odds_ratio,\n",
    "    definition=[genes],)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_a_spline(key, genes,knots, odds_ratio=1):\n",
    "    a = la.distributions.NormalDualMixture(\n",
    "    key=key,\n",
    "    loc1=0.0,\n",
    "    scale1=0.1,\n",
    "    loc2=0.0,\n",
    "    scale2=1,\n",
    "    logit=odds_ratio,\n",
    "    definition=[genes, knots],)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = np.random.default_rng(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_adata_converter (model, complete=False, size=1000):\n",
    "    model.rootify()\n",
    "    observation = model\n",
    "\n",
    "    k = la.utils.key.StatefulKey(0)\n",
    "    minibatcher_validation = la.train.minibatching.Minibatcher(model.clean[0], k(), size=size,permute=False, complete=complete)\n",
    "    minibatcher_validation.initialize()\n",
    "    program = la.programs.Inference(root = model, minibatcher=minibatcher_validation)\n",
    "    observation.value(program)\n",
    "\n",
    "    \n",
    "    outputs = program.run_all(n=1)\n",
    "    arrays = np.concat([output[(\"root\", \"value\")] for output in outputs])\n",
    "    # Stack arrays along a new axis and compute the mean\n",
    "    observation_value = arrays\n",
    "    adata = sc.AnnData(\n",
    "    observation_value,\n",
    "    )\n",
    "\n",
    "    sc.pp.pca(adata)\n",
    "    sc.pp.neighbors(adata)\n",
    "    sc.tl.umap(adata)\n",
    "    return adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(genes, logit, x_fixed_list):\n",
    "    generator = np.random.default_rng(1)\n",
    "    x1 = x_fixed_list[0]\n",
    "    x2 = x_fixed_list[1]\n",
    "    x3 = x_fixed_list[2]\n",
    "    # x1 effect\n",
    "    knots = la.Dim(5, name=\"knot\")\n",
    "    knot_positions = la.Fixed(\n",
    "        np.linspace(0.0, 1.0, len(knots)), definition=[knots], label=\"knot_positions\"\n",
    "    )\n",
    "    circular_knot_positions = la.Fixed(\n",
    "        np.linspace(0.0, 2 * np.pi, len(knots)),\n",
    "        definition=[knots],\n",
    "        label=\"circular_knot_positions\",\n",
    "    )\n",
    "    key=generator.integers(0, 10000)\n",
    "    a = create_a(key, genes, logit)\n",
    "\n",
    "    import math\n",
    "    x1_effect = la.links.scalar.Linear(x=x1, a=a, label=\"x1_effect\")\n",
    "\n",
    "    oi = la.Fixed(1)\n",
    "\n",
    "    # x2 effect\n",
    "    key=generator.integers(0, 10000)\n",
    "    a = create_a(key, genes)\n",
    "    shift = la.Fixed(generator.normal(0.5, 0.3, size=len(genes)), definition=[genes], label=\"shift\")\n",
    "    a_real = la.links.scalar.Linear(x=oi, a=a)\n",
    "    x2_effect = la.links.scalar.Sigmoid(x=x2, a=a_real, label=\"x2_effect\")\n",
    "\n",
    "    # x3 effect\n",
    "    key=generator.integers(0, 10000)\n",
    "    a = create_a(key, genes)\n",
    "\n",
    "    import math\n",
    "    x3_effect = la.links.scalar.Linear(\n",
    "        x=x3, a=a,  label=\"x3_effect\")\n",
    "    y = la.modular.Additive(definition=[cells, genes], transforms=[la.transforms.Exp()])\n",
    "    y.x1_effect = x1_effect\n",
    "    y.x2_effect = x2_effect\n",
    "    y.x3_effect = x3_effect\n",
    "    y.b = b\n",
    "    dispersion_value = np.clip(generator.gamma(1.0, 1.0, size=len(genes)), 2, 1)\n",
    "    dispersion = la.Fixed(dispersion_value, definition=[genes], label=\"dispersion\")\n",
    "    distribution = la.distributions.NegativeBinomial2(key=1, mu=y, dispersion=dispersion)\n",
    "    distribution.rootify()\n",
    "    program = la.Program()\n",
    "    distribution.value(program)\n",
    "    y.value(program)\n",
    "    y.find(\"Linear1\").value(program)\n",
    "    y.find(\"Sigmoid2\").value(program)\n",
    "    y.find(\"Linear3\").value(program)\n",
    "    y.x1_effect.value(program)\n",
    "    y.x2_effect.value(program)\n",
    "    y.x3_effect.value(program)\n",
    "    observation_value = np.asarray(program.run()[(\"root\", \"value\")])\n",
    "    y_value = np.asarray(program.run()[(\"root.mu\", \"value\")])\n",
    "    x1_value = np.asarray(program.run()[(y.find(\"Linear1\").uuid, \"value\")])\n",
    "    x2_value = np.asarray(program.run()[(y.find(\"Sigmoid2\").uuid, \"value\")])\n",
    "    x3_value = np.asarray(program.run()[(y.find(\"Linear3\").uuid, \"value\")])\n",
    "    x1_effect_value = np.asarray(program.run()[(y.x1_effect.uuid, \"value\")])\n",
    "    x2_effect_value = np.asarray(program.run()[(y.x2_effect.uuid, \"value\")])\n",
    "    x3_effect_value = np.asarray(program.run()[(y.x3_effect.uuid, \"value\")])\n",
    "    import scanpy as sc\n",
    "\n",
    "    adata = sc.AnnData(\n",
    "        observation_value,\n",
    "        obs=pd.DataFrame(\n",
    "            {\n",
    "                \"Linear1\": x1.prior_pd(),\n",
    "                \"Sigmoid2\": x2.prior_pd(),\n",
    "                \"Linear3\": x3.prior_pd(),\n",
    "            }\n",
    "        ),\n",
    "    )\n",
    "    sc.pp.pca(adata)\n",
    "    sc.pp.neighbors(adata)\n",
    "    sc.tl.umap(adata)\n",
    "\n",
    "    \n",
    "    return adata, distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = la.Fixed(generator.uniform(size=len(cells)), definition=[cells], label=\"Linear1\")\n",
    "x2 = la.Fixed(generator.uniform(size=len(cells)), definition=[cells], label=\"Sigmoid2\")\n",
    "x3 = la.Fixed(generator.uniform(size=len(cells)), definition=[cells], label=\"Linear3\")\n",
    "adata, model = create_data(genes, 1,[x1,x2,x3])\n",
    "\n",
    "model.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.X.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eyck\n",
    "eyck.m.t.plot_umap(adata, color=[\"Linear1\", \"Sigmoid2\", \"Linear3\"], cmap = \"magma\").display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic0 = time.time()\n",
    "sc.pp.pca(adata)\n",
    "toc0 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factors = 5\n",
    "# Import necessary libraries\n",
    "from sklearn.decomposition import FastICA\n",
    "tic1 = time.time()\n",
    "ica = FastICA(n_components=factors, random_state=42)\n",
    "X_transformed = ica.fit_transform(adata.X)\n",
    "toc1 = time.time()\n",
    "components = ica.components_.T\n",
    "adata.obsm[\"X_ica\"] = X_transformed\n",
    "# NMF\n",
    "from sklearn.decomposition import NMF\n",
    "tic2 = time.time()\n",
    "nmf = NMF(n_components=factors, random_state=42)\n",
    "X_transformed = nmf.fit_transform(adata.X)\n",
    "toc2 = time.time()\n",
    "components = nmf.components_.T\n",
    "adata.obsm[\"X_nmf\"] = X_transformed\n",
    "# SparsePCA\n",
    "from sklearn.decomposition import SparsePCA\n",
    "tic3 = time.time()\n",
    "pca = SparsePCA(n_components=factors, random_state=42, alpha = 2)\n",
    "X_transformed = pca.fit_transform(adata.X)\n",
    "toc3 = time.time()\n",
    "\n",
    "components = pca.components_.T\n",
    "adata.obsm[\"X_sparsepca_5\"] = X_transformed\n",
    "\n",
    "# Factor analysis\n",
    "from sklearn.decomposition import FactorAnalysis\n",
    "tic4 = time.time()\n",
    "fa = FactorAnalysis(n_components=factors, random_state=42)\n",
    "X_transformed = fa.fit_transform(adata.X)\n",
    "toc4 = time.time()\n",
    "\n",
    "components = fa.components_.T\n",
    "adata.obsm[\"X_fa\"] = X_transformed\n",
    "# Isomap\n",
    "from sklearn.manifold import Isomap\n",
    "tic5 = time.time()\n",
    "isomap = Isomap(n_components=factors)\n",
    "X_transformed = isomap.fit_transform(adata.X)\n",
    "toc5 = time.time()\n",
    "\n",
    "components = isomap.embedding_.T\n",
    "adata.obsm[\"X_isomap\"] = X_transformed\n",
    "# Spectral\n",
    "from sklearn.manifold import SpectralEmbedding\n",
    "tic6 = time.time()\n",
    "spectral = SpectralEmbedding(n_components=factors)\n",
    "X_transformed = spectral.fit_transform(adata.X)\n",
    "toc6 = time.time()\n",
    "\n",
    "components = spectral.embedding_.T\n",
    "adata.obsm[\"X_spectral\"] = X_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tictoc (tic, toc):\n",
    "    return toc - tic\n",
    "names = [\"pca\", 'X_ica','X_nmf', 'X_sparsepca_5', 'X_fa', 'X_isomap', 'X_spectral']\n",
    "tictoc_list = [(tic0,toc0),(tic1,toc1),(tic2,toc2),(tic3,toc3),(tic4,toc4),(tic5,toc5),(tic6,toc6)]\n",
    "for i,(tic, toc) in enumerate(tictoc_list):\n",
    "    print(names[i])\n",
    "    print(tictoc(tic, toc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = [\"X_pca\",\"X_sparsepca_5\"]\n",
    "names = [\"PCA\", \"X_sparsepca_5\"]\n",
    "for index,method in enumerate(methods):\n",
    "    fig = pp.grid.Figure(pp.grid.Grid(padding_height=0, padding_width=0))\n",
    "\n",
    "    grid = fig.main[1, 1] = pp.grid.Grid(padding_height=0.01, padding_width=0.01)\n",
    "    s = 0.5\n",
    "\n",
    "    w = 0.5\n",
    "    h = 0.5\n",
    "\n",
    "    max_n = 1000\n",
    "\n",
    "    rows = pd.DataFrame({\n",
    "        \"name\":[\"Linear1\", \"Sigmoid2\", \"Linear3\"],\n",
    "    })\n",
    "    rows[\"ix\"] = range(len(rows))\n",
    "    rows = rows.set_index(\"name\")\n",
    "\n",
    "\n",
    "    columns = pd.DataFrame({\n",
    "        \"name\":[f\"IC{i+1}\" for i in range(min(adata.obsm[method].shape[1], 5))],\n",
    "    })\n",
    "    columns[\"ix\"] = range(len(columns))\n",
    "    columns = columns.set_index(\"name\")\n",
    "\n",
    "    for row_name, (i, ) in rows.iterrows():\n",
    "        panel, ax = grid[i + 1, 0] = pp.grid.Panel((w, h))\n",
    "        ax.text(0.4, 0.5, row_name, ha=\"center\", va=\"center\")\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    for i in columns[\"ix\"]:\n",
    "        panel, ax = grid[0, i + 1] = pp.grid.Panel((w, h))\n",
    "        ax.text(0.5, 0.5, f\"x{i+1}\", ha=\"center\", va=\"center\")\n",
    "        ax.axis(\"off\")  \n",
    "\n",
    "    for row_name, (i, ) in rows.iterrows():\n",
    "        for column_name, (j, ) in columns.iterrows():\n",
    "            x = adata.obs[row_name]\n",
    "            y = adata.obsm[method][:, j]\n",
    "            panel, ax = grid[i+1, j+1] = pp.grid.Panel((w, h))\n",
    "            ax.scatter(x, y, s=0.5)\n",
    "            cor = np.corrcoef(x, y)[0, 1]\n",
    "            text = ax.text(0.5, 0.5, f\"{cor:.2f}\", transform=ax.transAxes, ha=\"center\", va=\"center\")\n",
    "            text.set_path_effects(\n",
    "                [\n",
    "                    mpl.patheffects.Stroke(linewidth=3, foreground=\"white\"),\n",
    "                    mpl.patheffects.Normal(),\n",
    "                ]\n",
    "            )\n",
    "            ax.axis(\"off\")\n",
    "    fig.main.align()\n",
    "\n",
    "    horizontal = fig.main[0, 1] = pp.grid.Panel((grid.width, 0.2))\n",
    "    horizontal.axis(\"off\")\n",
    "    horizontal.text(0.5, 0.5, names[index], va=\"center\", ha=\"center\")\n",
    "\n",
    "    vertical = fig.main[1, 0] = pp.grid.Panel((0.2, grid.height))\n",
    "    vertical.axis(\"off\")\n",
    "    vertical.text(-0.5, 0.5, \"Real\", rotation=90, va=\"center\", ha=\"center\")\n",
    "    # Add a top-left title\n",
    "    top_left = fig.main[0, 0] = pp.grid.Panel((0.4, 0.2))  # Adjust width and height as needed\n",
    "    top_left.axis(\"off\")\n",
    "    top_left.text(0.5, 0.5, \"Simple model\", va=\"center\", ha=\"center\", fontsize=12, fontweight=\"bold\")\n",
    "    fig.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(\"..\", \"synthetic_data\", \"no_dependencies_simple_synthetic_data.pkl\")\n",
    "os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "\n",
    "with open(path, \"wb\") as f:\n",
    "    pickle.dump(adata, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import latenta.links.vector.binary_multidimensional_spline as bms\n",
    "import latenta.distributions.binary_multidimensional_spline as bms_dist\n",
    "\n",
    "expdim = 4\n",
    "n_dimensions = 3\n",
    "a_zooms, a_dimensions = bms.create_zooms(expdim, n_dimensions, expdim_min=1)\n",
    "a_split = bms.create_a_values(a_zooms, a_dimensions, n_dimensions)\n",
    "\n",
    "a_values = dict(zip(zip(a_zooms, a_dimensions), a_split))\n",
    "\n",
    "# a_values: default at 0\n",
    "# \n",
    "a_values[(2, (0,))] = a_values[(2, (0,))].at[2].set(2.0)\n",
    "a_values[(3, (0, 2))] = a_values[(3, (0, 2))].at[0, :, 2].set(2.0)\n",
    "a_values[(2, (0, 1, 2))] = a_values[(2, (0, 1, 2))].at[1, 5, 2].set(1.0)\n",
    "a_split = tuple(a_values.values())\n",
    "\n",
    "a_concatenated, splits, shapes = bms.concatenate_a(a_split)\n",
    "a = la.Fixed(a_concatenated, definition=[la.Dim(len(a_concatenated), name=\"a\")], label=\"a\")\n",
    "dist = bms_dist.BinaryMultidimensionalSplineDistribution(\n",
    "    a,\n",
    "    zooms=a_zooms,\n",
    "    dimensions=a_dimensions,\n",
    "    n_dimensions=n_dimensions,\n",
    "    zoom=4,\n",
    "    kernel=\"normal\",\n",
    "    key=10\n",
    ")\n",
    "X = dist.prior(shape=(len(cells), n_dimensions))\n",
    "plt.hist(X)\n",
    "x1 = la.Fixed(X[:, 0], definition=[cells], label=\"Linear1\")\n",
    "x2 = la.Fixed(X[:, 1], definition=[cells], label=\"Sigmoid2\")\n",
    "x3 = la.Fixed(X[:, 2], definition=[cells], label=\"Linear3\")\n",
    "\n",
    "generator = np.random.default_rng(1)\n",
    "b_value = generator.normal(1, scale=0.5, size=len(genes))\n",
    "b = la.Fixed(b_value, definition=[genes], label=\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata,model = create_data(genes, 0.5,[x1,x2,x3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.X.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eyck\n",
    "eyck.m.t.plot_umap(adata, color=[\"Linear1\", \"Sigmoid2\", \"Linear3\"], cmap = \"magma\").display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def factor_analysis(factors, adata):\n",
    "    # Import necessary libraries\n",
    "    from sklearn.decomposition import FastICA\n",
    "    ica = FastICA(n_components=factors, random_state=42)\n",
    "    X_transformed = ica.fit_transform(adata.X)\n",
    "    components = ica.components_.T\n",
    "    adata.obsm[\"X_ica\"] = X_transformed\n",
    "    # NMF\n",
    "    from sklearn.decomposition import NMF\n",
    "    nmf = NMF(n_components=factors, random_state=42)\n",
    "    X_transformed = nmf.fit_transform(adata.X)\n",
    "    components = nmf.components_.T\n",
    "    adata.obsm[\"X_nmf\"] = X_transformed\n",
    "    # SparsePCA\n",
    "    from sklearn.decomposition import SparsePCA\n",
    "    pca = SparsePCA(n_components=factors, random_state=42, alpha = 2)\n",
    "    X_transformed = pca.fit_transform(adata.X)\n",
    "    components = pca.components_.T\n",
    "    adata.obsm[\"X_sparsepca_5\"] = X_transformed\n",
    "\n",
    "    # Factor analysis\n",
    "    from sklearn.decomposition import FactorAnalysis\n",
    "    fa = FactorAnalysis(n_components=factors, random_state=42)\n",
    "    X_transformed = fa.fit_transform(adata.X)\n",
    "    components = fa.components_.T\n",
    "    adata.obsm[\"X_fa\"] = X_transformed\n",
    "    # Isomap\n",
    "    from sklearn.manifold import Isomap\n",
    "    isomap = Isomap(n_components=factors)\n",
    "    X_transformed = isomap.fit_transform(adata.X)\n",
    "    components = isomap.embedding_.T\n",
    "    adata.obsm[\"X_isomap\"] = X_transformed\n",
    "    # Spectral\n",
    "    from sklearn.manifold import SpectralEmbedding\n",
    "    spectral = SpectralEmbedding(n_components=factors)\n",
    "    X_transformed = spectral.fit_transform(adata.X)\n",
    "    components = spectral.embedding_.T\n",
    "    adata.obsm[\"X_spectral\"] = X_transformed\n",
    "factor_analysis(5, adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = [\"X_pca\",\"X_sparsepca_5\"]\n",
    "names = [\"PCA\", \"X_sparsepca_5\"]\n",
    "for index,method in enumerate(methods):\n",
    "    fig = pp.grid.Figure(pp.grid.Grid(padding_height=0, padding_width=0))\n",
    "\n",
    "    grid = fig.main[1, 1] = pp.grid.Grid(padding_height=0.01, padding_width=0.01)\n",
    "    s = 0.5\n",
    "\n",
    "    w = 0.5\n",
    "    h = 0.5\n",
    "\n",
    "    max_n = 1000\n",
    "\n",
    "    rows = pd.DataFrame({\n",
    "        \"name\":[\"Linear1\", \"Sigmoid2\", \"Linear3\"],\n",
    "    })\n",
    "    rows[\"ix\"] = range(len(rows))\n",
    "    rows = rows.set_index(\"name\")\n",
    "\n",
    "\n",
    "    columns = pd.DataFrame({\n",
    "        \"name\":[f\"IC{i+1}\" for i in range(min(adata.obsm[method].shape[1], 5))],\n",
    "    })\n",
    "    columns[\"ix\"] = range(len(columns))\n",
    "    columns = columns.set_index(\"name\")\n",
    "\n",
    "    for row_name, (i, ) in rows.iterrows():\n",
    "        panel, ax = grid[i + 1, 0] = pp.grid.Panel((w, h))\n",
    "        ax.text(0.4, 0.5, row_name, ha=\"center\", va=\"center\")\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    for i in columns[\"ix\"]:\n",
    "        panel, ax = grid[0, i + 1] = pp.grid.Panel((w, h))\n",
    "        ax.text(0.5, 0.5, f\"x{i+1}\", ha=\"center\", va=\"center\")\n",
    "        ax.axis(\"off\")  \n",
    "\n",
    "    for row_name, (i, ) in rows.iterrows():\n",
    "        for column_name, (j, ) in columns.iterrows():\n",
    "            x = adata.obs[row_name]\n",
    "            y = adata.obsm[method][:, j]\n",
    "            panel, ax = grid[i+1, j+1] = pp.grid.Panel((w, h))\n",
    "            ax.scatter(x, y, s=0.5)\n",
    "            cor = np.corrcoef(x, y)[0, 1]\n",
    "            text = ax.text(0.5, 0.5, f\"{cor:.2f}\", transform=ax.transAxes, ha=\"center\", va=\"center\")\n",
    "            text.set_path_effects(\n",
    "                [\n",
    "                    mpl.patheffects.Stroke(linewidth=3, foreground=\"white\"),\n",
    "                    mpl.patheffects.Normal(),\n",
    "                ]\n",
    "            )\n",
    "            ax.axis(\"off\")\n",
    "    fig.main.align()\n",
    "\n",
    "    horizontal = fig.main[0, 1] = pp.grid.Panel((grid.width, 0.2))\n",
    "    horizontal.axis(\"off\")\n",
    "    horizontal.text(0.5, 0.5, names[index], va=\"center\", ha=\"center\")\n",
    "\n",
    "    vertical = fig.main[1, 0] = pp.grid.Panel((0.2, grid.height))\n",
    "    vertical.axis(\"off\")\n",
    "    vertical.text(-0.5, 0.5, \"Real\", rotation=90, va=\"center\", ha=\"center\")\n",
    "    # Add a top-left title\n",
    "    top_left = fig.main[0, 0] = pp.grid.Panel((0.4, 0.2))  # Adjust width and height as needed\n",
    "    top_left.axis(\"off\")\n",
    "    top_left.text(0.5, 0.5, \"Simple model\", va=\"center\", ha=\"center\", fontsize=12, fontweight=\"bold\")\n",
    "    fig.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(\"..\", \"synthetic_data\", \"dependencies_simple_synthetic_data.pkl\")\n",
    "os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "\n",
    "with open(path, \"wb\") as f:\n",
    "    pickle.dump(adata, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non_linear synthetic data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes = la.Dim(500, name=\"gene\")\n",
    "cells = la.Dim(2000, name=\"cell\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_a(key, genes, odds_ratio=1):\n",
    "    a = la.distributions.NormalDualMixture(\n",
    "    key=key,\n",
    "    loc1=0.0,\n",
    "    scale1=0.1,\n",
    "    loc2=0.0,\n",
    "    scale2=1,\n",
    "    logit=odds_ratio,\n",
    "    definition=[genes],)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_a_spline(key, genes,knots, odds_ratio=1):\n",
    "    a = la.distributions.NormalDualMixture(\n",
    "    key=key,\n",
    "    loc1=0.0,\n",
    "    scale1=0.1,\n",
    "    loc2=0.0,\n",
    "    scale2=1,\n",
    "    logit=odds_ratio,\n",
    "    definition=[genes, knots],)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_complex(genes, logit, x_fixed_list = None):\n",
    "    x_effects = {}\n",
    "    generator = np.random.default_rng(1)\n",
    "    if not x_fixed_list:\n",
    "        x1 = la.Fixed(generator.uniform(size=len(cells)), definition=[cells], label=\"Spline1\")\n",
    "        x2 = la.Fixed(generator.uniform(size=len(cells)), definition=[cells], label=\"Logistic2\")\n",
    "        x3 = la.Fixed(generator.uniform(size=len(cells)), definition=[cells], label=\"CircularSpline3\")\n",
    "    else:\n",
    "        x1 = x_fixed_list[0]\n",
    "        x2 = x_fixed_list[1]\n",
    "        x3 = x_fixed_list[2]\n",
    "\n",
    "\n",
    "    # x1 effect\n",
    "    knots = la.Dim(10, name=\"knot\")\n",
    "    knot_positions = la.Fixed(\n",
    "        np.linspace(0.0, 1.0, len(knots)), definition=[knots], label=\"knot_positions\"\n",
    "    )\n",
    "    circular_knot_positions = la.Fixed(\n",
    "        np.linspace(0.0, 2 * np.pi, len(knots)),\n",
    "        definition=[knots],\n",
    "        label=\"circular_knot_positions\",\n",
    "    )\n",
    "    key=generator.integers(0, 10000)\n",
    "    a = create_a_spline(key, genes,knots, logit)\n",
    "\n",
    "    import math\n",
    "    x1_effect = la.links.scalar.Spline(x=x1, a=a, knot=knot_positions, label=\"x1_effect\")\n",
    "    x_effects[\"x1_effect\"] = (x1_effect) \n",
    "\n",
    "    oi = la.Fixed(1)\n",
    "\n",
    "    # x2 effect\n",
    "    key=generator.integers(0, 10000)\n",
    "    a = create_a(key, genes)\n",
    "    shift = la.Fixed(generator.normal(0.5, 0.3, size=len(genes)), definition=[genes], label=\"shift\")\n",
    "    a_real = la.links.scalar.Linear(x=oi, a=a)\n",
    "    x2_effect = la.links.scalar.Logistic(x=x2, a=a_real, shift = shift, skew = 20., label=\"x2_effect\")\n",
    "    x_effects[\"x2_effect\"] = (x2_effect) \n",
    "    # x3 effect\n",
    "    key=generator.integers(0, 10000)\n",
    "    a = create_a_spline(key, genes,knots, logit)\n",
    "\n",
    "    import math\n",
    "    x3_effect = la.links.scalar.CircularSpline(\n",
    "    x=la.links.scalar.Linear(x3, a = 2*math.pi), a=a, knot=circular_knot_positions, label=\"x3_effect\", smoothness=2\n",
    ")\n",
    "    x_effects[\"x3_effect\"] = (x3_effect) \n",
    "    y = la.modular.Additive(definition=[cells, genes], transforms=[la.transforms.Exp()])\n",
    "    y.x1_effect = x1_effect\n",
    "    y.x2_effect = x2_effect\n",
    "    y.x3_effect = x3_effect\n",
    "    y.b = b\n",
    "    dispersion_value = np.clip(generator.gamma(1.0, 1.0, size=len(genes)), 2, 1)\n",
    "    dispersion = la.Fixed(dispersion_value, definition=[genes], label=\"dispersion\")\n",
    "    distribution = la.distributions.NegativeBinomial2(key=1, mu=y, dispersion=dispersion)\n",
    "    distribution.rootify()\n",
    "    program = la.Program()\n",
    "    distribution.value(program)\n",
    "    y.value(program)\n",
    "    y.find(\"Spline1\").value(program)\n",
    "    y.find(\"Logistic2\").value(program)\n",
    "    y.find(\"CircularSpline3\").value(program)\n",
    "    y.x1_effect.value(program)\n",
    "    y.x2_effect.value(program)\n",
    "    y.x3_effect.value(program)\n",
    "\n",
    "    observation_value = np.asarray(program.run()[(\"root\", \"value\")])\n",
    "    y_value = np.asarray(program.run()[(\"root.mu\", \"value\")])\n",
    "    x1_value = np.asarray(program.run()[(y.find(\"Spline1\").uuid, \"value\")])\n",
    "    x2_value = np.asarray(program.run()[(y.find(\"Logistic2\").uuid, \"value\")])\n",
    "    x3_value = np.asarray(program.run()[(y.find(\"CircularSpline3\").uuid, \"value\")])\n",
    "    x1_effect_value = np.asarray(program.run()[(y.x1_effect.uuid, \"value\")])\n",
    "    x2_effect_value = np.asarray(program.run()[(y.x2_effect.uuid, \"value\")])\n",
    "    x3_effect_value = np.asarray(program.run()[(y.x3_effect.uuid, \"value\")])\n",
    "    import scanpy as sc\n",
    "\n",
    "    adata = sc.AnnData(\n",
    "        observation_value,\n",
    "        obs=pd.DataFrame(\n",
    "            {\n",
    "                \"Spline1\": x1.prior_pd(),\n",
    "                \"Logistic2\": x2.prior_pd(),\n",
    "                \"CircularSpline3\": x3.prior_pd(),\n",
    "            }\n",
    "        ),\n",
    "    )[:5000]\n",
    "\n",
    "    sc.pp.pca(adata)\n",
    "    sc.pp.neighbors(adata)\n",
    "    sc.tl.umap(adata)\n",
    "    return adata, distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata, model = create_data_complex(genes, 0.5)\n",
    "model.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eyck\n",
    "eyck.m.t.plot_umap(adata, color=[\"Spline1\", \"Logistic2\", \"CircularSpline3\"], cmap = \"magma\").display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factors = 5\n",
    "# Import necessary libraries\n",
    "from sklearn.decomposition import FastICA\n",
    "ica = FastICA(n_components=factors, random_state=42)\n",
    "X_transformed = ica.fit_transform(adata.X)\n",
    "components = ica.components_.T\n",
    "adata.obsm[\"X_ica\"] = X_transformed\n",
    "# NMF\n",
    "from sklearn.decomposition import NMF\n",
    "nmf = NMF(n_components=factors, random_state=42)\n",
    "X_transformed = nmf.fit_transform(adata.X)\n",
    "components = nmf.components_.T\n",
    "adata.obsm[\"X_nmf\"] = X_transformed\n",
    "# SparsePCA\n",
    "from sklearn.decomposition import SparsePCA\n",
    "pca = SparsePCA(n_components=factors, random_state=42, alpha = 2)\n",
    "X_transformed = pca.fit_transform(adata.X)\n",
    "components = pca.components_.T\n",
    "adata.obsm[\"X_sparsepca_5\"] = X_transformed\n",
    "\n",
    "# Factor analysis\n",
    "from sklearn.decomposition import FactorAnalysis\n",
    "fa = FactorAnalysis(n_components=factors, random_state=42)\n",
    "X_transformed = fa.fit_transform(adata.X)\n",
    "components = fa.components_.T\n",
    "adata.obsm[\"X_fa\"] = X_transformed\n",
    "# Isomap\n",
    "from sklearn.manifold import Isomap\n",
    "isomap = Isomap(n_components=factors)\n",
    "X_transformed = isomap.fit_transform(adata.X)\n",
    "components = isomap.embedding_.T\n",
    "adata.obsm[\"X_isomap\"] = X_transformed\n",
    "# Spectral\n",
    "from sklearn.manifold import SpectralEmbedding\n",
    "spectral = SpectralEmbedding(n_components=factors)\n",
    "X_transformed = spectral.fit_transform(adata.X)\n",
    "components = spectral.embedding_.T\n",
    "adata.obsm[\"X_spectral\"] = X_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = [\"X_pca\",\"X_sparsepca_5\"]\n",
    "names = [\"PCA\", \"X_sparsepca_5\"]\n",
    "for index,method in enumerate(methods):\n",
    "    fig = pp.grid.Figure(pp.grid.Grid(padding_height=0, padding_width=0))\n",
    "\n",
    "    grid = fig.main[1, 1] = pp.grid.Grid(padding_height=0.01, padding_width=0.01)\n",
    "    s = 0.5\n",
    "\n",
    "    w = 0.5\n",
    "    h = 0.5\n",
    "\n",
    "    max_n = 1000\n",
    "\n",
    "    rows = pd.DataFrame({\n",
    "        \"name\":[\"Spline1\", \"Logistic2\", \"CircularSpline3\"],\n",
    "    })\n",
    "    rows[\"ix\"] = range(len(rows))\n",
    "    rows = rows.set_index(\"name\")\n",
    "\n",
    "\n",
    "    columns = pd.DataFrame({\n",
    "        \"name\":[f\"IC{i+1}\" for i in range(min(adata.obsm[method].shape[1], 5))],\n",
    "    })\n",
    "    columns[\"ix\"] = range(len(columns))\n",
    "    columns = columns.set_index(\"name\")\n",
    "\n",
    "    for row_name, (i, ) in rows.iterrows():\n",
    "        panel, ax = grid[i + 1, 0] = pp.grid.Panel((w, h))\n",
    "        ax.text(0.4, 0.5, row_name, ha=\"center\", va=\"center\")\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    for i in columns[\"ix\"]:\n",
    "        panel, ax = grid[0, i + 1] = pp.grid.Panel((w, h))\n",
    "        ax.text(0.5, 0.5, f\"x{i+1}\", ha=\"center\", va=\"center\")\n",
    "        ax.axis(\"off\")  \n",
    "\n",
    "    for row_name, (i, ) in rows.iterrows():\n",
    "        for column_name, (j, ) in columns.iterrows():\n",
    "            x = adata.obs[row_name]\n",
    "            y = adata.obsm[method][:, j]\n",
    "            panel, ax = grid[i+1, j+1] = pp.grid.Panel((w, h))\n",
    "            ax.scatter(x, y, s=0.5)\n",
    "            cor = np.corrcoef(x, y)[0, 1]\n",
    "            text = ax.text(0.5, 0.5, f\"{cor:.2f}\", transform=ax.transAxes, ha=\"center\", va=\"center\")\n",
    "            text.set_path_effects(\n",
    "                [\n",
    "                    mpl.patheffects.Stroke(linewidth=3, foreground=\"white\"),\n",
    "                    mpl.patheffects.Normal(),\n",
    "                ]\n",
    "            )\n",
    "            ax.axis(\"off\")\n",
    "    fig.main.align()\n",
    "\n",
    "    horizontal = fig.main[0, 1] = pp.grid.Panel((grid.width, 0.2))\n",
    "    horizontal.axis(\"off\")\n",
    "    horizontal.text(0.5, 0.5, names[index], va=\"center\", ha=\"center\")\n",
    "\n",
    "    vertical = fig.main[1, 0] = pp.grid.Panel((0.2, grid.height))\n",
    "    vertical.axis(\"off\")\n",
    "    vertical.text(-0.5, 0.5, \"Real\", rotation=90, va=\"center\", ha=\"center\")\n",
    "    # Add a top-left title\n",
    "    top_left = fig.main[0, 0] = pp.grid.Panel((0.4, 0.2))  # Adjust width and height as needed\n",
    "    top_left.axis(\"off\")\n",
    "    top_left.text(0.5, 0.5, \"Simple model\", va=\"center\", ha=\"center\", fontsize=12, fontweight=\"bold\")\n",
    "    fig.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(\"..\", \"synthetic_data\", \"no_dependencies_complex_synthetic_data.pkl\")\n",
    "os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "\n",
    "with open(path, \"wb\") as f:\n",
    "    pickle.dump(adata, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import latenta.links.vector.binary_multidimensional_spline as bms\n",
    "import latenta.distributions.binary_multidimensional_spline as bms_dist\n",
    "\n",
    "expdim = 4\n",
    "n_dimensions = 3\n",
    "a_zooms, a_dimensions = bms.create_zooms(expdim, n_dimensions, expdim_min=1)\n",
    "a_split = bms.create_a_values(a_zooms, a_dimensions, n_dimensions)\n",
    "\n",
    "a_values = dict(zip(zip(a_zooms, a_dimensions), a_split))\n",
    "\n",
    "# a_values: default at 0\n",
    "# \n",
    "a_values[(2, (0,))] = a_values[(2, (0,))].at[2].set(2.0)\n",
    "a_values[(3, (0, 2))] = a_values[(3, (0, 2))].at[0, :, 2].set(2.0)\n",
    "a_values[(2, (0, 1, 2))] = a_values[(2, (0, 1, 2))].at[1, 5, 2].set(1.0)\n",
    "a_split = tuple(a_values.values())\n",
    "\n",
    "a_concatenated, splits, shapes = bms.concatenate_a(a_split)\n",
    "a = la.Fixed(a_concatenated, definition=[la.Dim(len(a_concatenated), name=\"a\")], label=\"a\")\n",
    "dist = bms_dist.BinaryMultidimensionalSplineDistribution(\n",
    "    a,\n",
    "    zooms=a_zooms,\n",
    "    dimensions=a_dimensions,\n",
    "    n_dimensions=n_dimensions,\n",
    "    zoom=4,\n",
    "    kernel=\"normal\",\n",
    "    key=10\n",
    ")\n",
    "X = dist.prior(shape=(len(cells), n_dimensions))\n",
    "plt.hist(X)\n",
    "x1 = la.Fixed(X[:, 0], definition=[cells], label=\"Spline1\")\n",
    "x2 = la.Fixed(X[:, 1], definition=[cells], label=\"Logistic2\")\n",
    "x3 = la.Fixed(X[:, 2], definition=[cells], label=\"CircularSpline3\")\n",
    "\n",
    "generator = np.random.default_rng(1)\n",
    "b_value = generator.normal(1, scale=0.5, size=len(genes))\n",
    "b = la.Fixed(b_value, definition=[genes], label=\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata,model = create_data_complex(genes, 0.5,[x1,x2,x3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.X.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eyck\n",
    "eyck.m.t.plot_umap(adata, color=[\"Spline1\", \"Logistic2\", \"CircularSpline3\"], cmap = \"magma\").display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def factor_analysis(factors, adata):\n",
    "    # Import necessary libraries\n",
    "    from sklearn.decomposition import FastICA\n",
    "    ica = FastICA(n_components=factors, random_state=42)\n",
    "    X_transformed = ica.fit_transform(adata.X)\n",
    "    components = ica.components_.T\n",
    "    adata.obsm[\"X_ica\"] = X_transformed\n",
    "    # NMF\n",
    "    from sklearn.decomposition import NMF\n",
    "    nmf = NMF(n_components=factors, random_state=42)\n",
    "    X_transformed = nmf.fit_transform(adata.X)\n",
    "    components = nmf.components_.T\n",
    "    adata.obsm[\"X_nmf\"] = X_transformed\n",
    "    # SparsePCA\n",
    "    from sklearn.decomposition import SparsePCA\n",
    "    pca = SparsePCA(n_components=factors, random_state=42, alpha = 2)\n",
    "    X_transformed = pca.fit_transform(adata.X)\n",
    "    components = pca.components_.T\n",
    "    adata.obsm[\"X_sparsepca_5\"] = X_transformed\n",
    "\n",
    "    # Factor analysis\n",
    "    from sklearn.decomposition import FactorAnalysis\n",
    "    fa = FactorAnalysis(n_components=factors, random_state=42)\n",
    "    X_transformed = fa.fit_transform(adata.X)\n",
    "    components = fa.components_.T\n",
    "    adata.obsm[\"X_fa\"] = X_transformed\n",
    "    # Isomap\n",
    "    from sklearn.manifold import Isomap\n",
    "    isomap = Isomap(n_components=factors)\n",
    "    X_transformed = isomap.fit_transform(adata.X)\n",
    "    components = isomap.embedding_.T\n",
    "    adata.obsm[\"X_isomap\"] = X_transformed\n",
    "    # Spectral\n",
    "    from sklearn.manifold import SpectralEmbedding\n",
    "    spectral = SpectralEmbedding(n_components=factors)\n",
    "    X_transformed = spectral.fit_transform(adata.X)\n",
    "    components = spectral.embedding_.T\n",
    "    adata.obsm[\"X_spectral\"] = X_transformed\n",
    "factor_analysis(5, adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = [\"X_pca\",\"X_sparsepca_5\"]\n",
    "names = [\"PCA\", \"X_sparsepca_5\"]\n",
    "for index,method in enumerate(methods):\n",
    "    fig = pp.grid.Figure(pp.grid.Grid(padding_height=0, padding_width=0))\n",
    "\n",
    "    grid = fig.main[1, 1] = pp.grid.Grid(padding_height=0.01, padding_width=0.01)\n",
    "    s = 0.5\n",
    "\n",
    "    w = 0.5\n",
    "    h = 0.5\n",
    "\n",
    "    max_n = 1000\n",
    "\n",
    "    rows = pd.DataFrame({\n",
    "        \"name\":[\"Spline1\", \"Logistic2\", \"CircularSpline3\"],\n",
    "    })\n",
    "    rows[\"ix\"] = range(len(rows))\n",
    "    rows = rows.set_index(\"name\")\n",
    "\n",
    "\n",
    "    columns = pd.DataFrame({\n",
    "        \"name\":[f\"IC{i+1}\" for i in range(min(adata.obsm[method].shape[1], 5))],\n",
    "    })\n",
    "    columns[\"ix\"] = range(len(columns))\n",
    "    columns = columns.set_index(\"name\")\n",
    "\n",
    "    for row_name, (i, ) in rows.iterrows():\n",
    "        panel, ax = grid[i + 1, 0] = pp.grid.Panel((w, h))\n",
    "        ax.text(0.4, 0.5, row_name, ha=\"center\", va=\"center\")\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    for i in columns[\"ix\"]:\n",
    "        panel, ax = grid[0, i + 1] = pp.grid.Panel((w, h))\n",
    "        ax.text(0.5, 0.5, f\"x{i+1}\", ha=\"center\", va=\"center\")\n",
    "        ax.axis(\"off\")  \n",
    "\n",
    "    for row_name, (i, ) in rows.iterrows():\n",
    "        for column_name, (j, ) in columns.iterrows():\n",
    "            x = adata.obs[row_name]\n",
    "            y = adata.obsm[method][:, j]\n",
    "            panel, ax = grid[i+1, j+1] = pp.grid.Panel((w, h))\n",
    "            ax.scatter(x, y, s=0.5)\n",
    "            cor = np.corrcoef(x, y)[0, 1]\n",
    "            text = ax.text(0.5, 0.5, f\"{cor:.2f}\", transform=ax.transAxes, ha=\"center\", va=\"center\")\n",
    "            text.set_path_effects(\n",
    "                [\n",
    "                    mpl.patheffects.Stroke(linewidth=3, foreground=\"white\"),\n",
    "                    mpl.patheffects.Normal(),\n",
    "                ]\n",
    "            )\n",
    "            ax.axis(\"off\")\n",
    "    fig.main.align()\n",
    "\n",
    "    horizontal = fig.main[0, 1] = pp.grid.Panel((grid.width, 0.2))\n",
    "    horizontal.axis(\"off\")\n",
    "    horizontal.text(0.5, 0.5, names[index], va=\"center\", ha=\"center\")\n",
    "\n",
    "    vertical = fig.main[1, 0] = pp.grid.Panel((0.2, grid.height))\n",
    "    vertical.axis(\"off\")\n",
    "    vertical.text(-0.5, 0.5, \"Real\", rotation=90, va=\"center\", ha=\"center\")\n",
    "    # Add a top-left title\n",
    "    top_left = fig.main[0, 0] = pp.grid.Panel((0.4, 0.2))  # Adjust width and height as needed\n",
    "    top_left.axis(\"off\")\n",
    "    top_left.text(0.5, 0.5, \"Simple model\", va=\"center\", ha=\"center\", fontsize=12, fontweight=\"bold\")\n",
    "    fig.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(\"..\", \"synthetic_data\", \"dependencies_complex_synthetic_data.pkl\")\n",
    "os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "\n",
    "with open(path, \"wb\") as f:\n",
    "    pickle.dump(adata, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "latenta",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
